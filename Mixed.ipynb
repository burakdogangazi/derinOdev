{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2b6e188",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Set Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddb820c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- General Libraries ---\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# --- Data Handling ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# --- Image Handling and Visualization ---\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "\n",
    "# --- PyTorch and Deep Learning ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "\n",
    "# --- Utilities ---\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "\n",
    "# --- Warning Suppression ---\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f861defc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device for PyTorch computations\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Print device information\n",
    "print(f\"Using {device} device\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# If CUDA is available, print additional details\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Number of CUDA Devices: {torch.cuda.device_count()}\")\n",
    "    print(f\"Current CUDA Device: {torch.cuda.current_device()}\")\n",
    "    print(f\"CUDA Device Name: {torch.cuda.get_device_name(torch.cuda.current_device())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b8b13b",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4752e7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"lung_colon_image_set\"\n",
    "image_paths = []\n",
    "multi_labels = []\n",
    "\n",
    "label_mapping = {\n",
    "    'lung_n': 0, 'lung_aca': 1, 'lung_scc': 2,\n",
    "    'colon_n': 3, 'colon_aca': 4\n",
    "}\n",
    "\n",
    "class_names = list(label_mapping.keys())\n",
    "\n",
    "# Yeni modelde artık sadece multiclass etiketlemeyi kullanıyoruz\n",
    "for subfolder in ['lung_image_sets/lung_n', 'lung_image_sets/lung_aca', 'lung_image_sets/lung_scc',\n",
    "                  'colon_image_sets/colon_n', 'colon_image_sets/colon_aca']:\n",
    "    class_dir = os.path.join(root_dir, subfolder)\n",
    "    class_name = subfolder.split('/')[-1]\n",
    "\n",
    "    for img_file in os.listdir(class_dir):\n",
    "        img_path = os.path.join(class_dir, img_file)\n",
    "        image_paths.append(img_path)\n",
    "        multi_labels.append(label_mapping[class_name])\n",
    "\n",
    "print(f\"Total Image: {len(image_paths)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098b64cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(), \n",
    "    transforms.RandomRotation(15),  \n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),  # Random color jitter\n",
    "    transforms.RandomZoom(0.1), \n",
    "    transforms.RandomVerticalFlip(), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalization\n",
    "])\n",
    "\n",
    "# Regular transform for test/validation data (no augmentation)\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb414f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureDataset(Dataset):\n",
    "    def __init__(self, image_paths, multi_labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.multi_labels = multi_labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, self.multi_labels[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c6e132",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(image_paths, multi_labels, test_size=0.3, random_state=42, stratify=multi_labels)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "# Create datasets with respective transformations\n",
    "train_dataset = FeatureDataset(X_train, y_train, transform=train_transform)\n",
    "val_dataset = FeatureDataset(X_val, y_val, transform=test_transform)\n",
    "test_dataset = FeatureDataset(X_test, y_test, transform=test_transform)\n",
    "\n",
    "# Create data loaders for train, validation, and test datasets\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6318d3",
   "metadata": {},
   "source": [
    "## 3. EfficientNetB3 + Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817a065a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.efficientnet_b3(weights=models.EfficientNet_B3_Weights.DEFAULT)\n",
    "model.classifier = torch.nn.Identity() \n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5416671e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(dataloader):\n",
    "    all_features = []\n",
    "    all_bin_labels = []\n",
    "    all_multi_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, bin_labels, multi_labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            features = model(inputs)\n",
    "            all_features.append(features.cpu().numpy())\n",
    "            all_bin_labels.extend(bin_labels)\n",
    "            all_multi_labels.extend(multi_labels)\n",
    "\n",
    "    return np.concatenate(all_features), np.array(all_bin_labels), np.array(all_multi_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7274f55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_feat, y_bin_train, y_multi_train = extract_features(train_loader)\n",
    "X_test_feat, y_bin_test, y_multi_test = extract_features(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754c9885",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_multi = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_multi.fit(X_train_feat, y_multi_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d210f6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_multi_pred = rf_multi.predict(X_test_feat)\n",
    "\n",
    "print(\"🔎 Multiclass Classification Report:\")\n",
    "print(classification_report(y_multi_test, y_multi_pred, target_names=[\n",
    "    \"Lung Benign\", \"Lung ACA\", \"Lung SCC\", \"Colon Benign\", \"Colon ACA\"\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afd0106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained RandomForest model\n",
    "save_path_rf = \"random_forest_model.pth\"\n",
    "joblib.dump(rf_multi, save_path_rf)\n",
    "print(f\"RandomForest model saved to {save_path_rf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c9a6d3",
   "metadata": {},
   "source": [
    "## 4. Resnet34 Classification Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aabc2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet34 modelini yükle\n",
    "resnet34 = models.resnet34(pretrained=True, weights=models.ResNet34_Weights.DEFAULT)\n",
    "\n",
    "# Son katmanı yeniden yapılandır\n",
    "num_ftrs = resnet34.fc.in_features  # ResNet34'ün son katmanının girdi özellikleri\n",
    "resnet34.fc = nn.Sequential(\n",
    "    nn.Linear(num_ftrs, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(512, len(class_names))  # Burada class_names, sınıf sayısına eşit olmalı\n",
    ")\n",
    "\n",
    "resnet34 = resnet34.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3af882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in tqdm(train_loader, desc=\"Training One Epoch\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()  # Clear gradients\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()  # Backpropagate the loss\n",
    "        optimizer.step()  # Update the weights\n",
    "\n",
    "        running_loss += loss.item()  # Sum the loss for average calculation\n",
    "        _, predicted = torch.max(outputs, 1)  # Get the class predictions\n",
    "        total += labels.size(0)  # Number of examples\n",
    "        correct += (predicted == labels).sum().item()  # Correct predictions count\n",
    "\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    train_accuracy = 100 * correct / total\n",
    "    return avg_train_loss, train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a457aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_one_epoch(model, val_loader, criterion, device):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    running_val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "\n",
    "    with torch.no_grad():  # No need to compute gradients during validation\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_val_loss += loss.item()  # Sum the loss for average calculation\n",
    "            _, predicted = torch.max(outputs, 1)  # Get the class predictions\n",
    "            total_val += labels.size(0)  # Number of examples\n",
    "            correct_val += (predicted == labels).sum().item()  # Correct predictions count\n",
    "\n",
    "    avg_val_loss = running_val_loss / len(val_loader)\n",
    "    val_accuracy = 100 * correct_val / total_val\n",
    "    return avg_val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320698d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, epochs=10, patience=3, device='cuda', save_path=\"best_resnet_model.pth\"):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    best_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    # Lists to store losses and accuracies for plotting\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Training phase (train for one epoch)\n",
    "        avg_train_loss, train_accuracy = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {avg_train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%\")\n",
    "\n",
    "        # Append training metrics to lists for plotting\n",
    "        train_losses.append(avg_train_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "\n",
    "        # Validation phase (validate for one epoch)\n",
    "        avg_val_loss, val_accuracy = validate_one_epoch(model, val_loader, criterion, device)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "        # Append validation metrics to lists for plotting\n",
    "        val_losses.append(avg_val_loss)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        if avg_val_loss < best_loss:\n",
    "            best_loss = avg_val_loss\n",
    "            patience_counter = 0  # Reset counter if validation loss improves\n",
    "\n",
    "            # Save the best model\n",
    "            print(\"Validation loss improved, saving the model...\")\n",
    "            torch.save(model.state_dict(), save_path)  # Save the best model\n",
    "\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "    return train_losses, val_losses, train_accuracies, val_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee6a60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, val_losses, train_accuracies, val_accuracies = train(model, train_loader, val_loader, epochs=50, patience=3, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd7e13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_metrics(train_losses, val_losses, train_accuracies, val_accuracies):\n",
    "    \"\"\"\n",
    "    Plot the training and validation loss and accuracy for each epoch.\n",
    "    \"\"\"\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "    # Plot loss values\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, train_losses, label='Train Loss', color='blue', marker='o')\n",
    "    plt.plot(epochs, val_losses, label='Validation Loss', color='red', marker='o')\n",
    "    plt.title('Loss over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot accuracy values\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, train_accuracies, label='Train Accuracy', color='blue', marker='o')\n",
    "    plt.plot(epochs, val_accuracies, label='Validation Accuracy', color='red', marker='o')\n",
    "    plt.title('Accuracy over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98113911",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train_metrics(train_losses, val_losses, train_accuracies, val_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a67c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, device='cuda', class_names=None):\n",
    "    model.eval()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    test_accuracy = (correct / total) * 100\n",
    "\n",
    "    print(f\"\\n🧪 Test Loss: {avg_test_loss:.4f}\")\n",
    "    print(f\"✅ Test Accuracy: {test_accuracy:.2f}%\")\n",
    "    \n",
    "    print(\"\\n📊 Classification Report:\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=class_names))\n",
    "\n",
    "    # 🔍 Confusion Matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return avg_test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fc1b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = test_model(model, test_loader, device='cuda', class_names=class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0861ad",
   "metadata": {},
   "source": [
    "## 5. Ensemble Method (Soft Voting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242575df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_predict_soft_voting(resnet_model, rf_model, test_loader, X_test_feat, y_test, class_names, device='cuda'):\n",
    "    resnet_model.eval()\n",
    "    all_ensemble_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    rf_probs_all = rf_model.predict_proba(X_test_feat)  # EfficientNet ile çıkarılan özelliklerden\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(test_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            resnet_outputs = resnet_model(images)\n",
    "            resnet_probs = torch.softmax(resnet_outputs, dim=1).cpu().numpy()\n",
    "\n",
    "            # Bu batch için RF tahminleri (aynı sırada alınmalı)\n",
    "            batch_size = images.size(0)\n",
    "            rf_probs = rf_probs_all[i * batch_size: (i + 1) * batch_size]\n",
    "\n",
    "            # Soft voting: average the probabilities\n",
    "            avg_probs = (resnet_probs + rf_probs) / 2\n",
    "            ensemble_preds = np.argmax(avg_probs, axis=1)\n",
    "\n",
    "            all_ensemble_preds.extend(ensemble_preds)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    print(\"\\nEnsemble Model Classification Report:\")\n",
    "    print(classification_report(all_labels, all_ensemble_preds, target_names=class_names))\n",
    "\n",
    "    return all_labels, all_ensemble_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64f5df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels, predicted_labels = ensemble_predict_soft_voting(\n",
    "    resnet_model=resnet34,\n",
    "    rf_model=rf_multi,\n",
    "    test_loader=test_loader,\n",
    "    class_names=class_names,\n",
    "    device='cuda'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
