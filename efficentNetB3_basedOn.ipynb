{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4777bdf8",
   "metadata": {
    "papermill": {
     "duration": 0.009896,
     "end_time": "2024-03-16T08:03:00.449654",
     "exception": false,
     "start_time": "2024-03-16T08:03:00.439758",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Import needed libraries and Set Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c1c6a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T08:03:00.469203Z",
     "iopub.status.busy": "2024-03-16T08:03:00.468874Z",
     "iopub.status.idle": "2024-03-16T08:03:15.111058Z",
     "shell.execute_reply": "2024-03-16T08:03:15.110163Z"
    },
    "papermill": {
     "duration": 14.654558,
     "end_time": "2024-03-16T08:03:15.113502",
     "exception": false,
     "start_time": "2024-03-16T08:03:00.458944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- General Libraries ---\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "# --- Data Handling Libraries ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --- Image Handling and Visualization ---\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "\n",
    "# --- PyTorch Libraries ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# --- Progress and Profiling ---\n",
    "from tqdm import tqdm  # For displaying progress during training\n",
    "import torch.profiler  # For tracking GPU usage during training\n",
    "\n",
    "# --- Warnings Handling ---\n",
    "warnings.filterwarnings('ignore')  # Ignore warnings for cleaner output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33cc41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13260370",
   "metadata": {
    "papermill": {
     "duration": 0.013127,
     "end_time": "2024-03-16T08:03:15.143475",
     "exception": false,
     "start_time": "2024-03-16T08:03:15.130348",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 2. Data Loading and Preprocessing\n",
    "\n",
    "In this section, we use `torchvision.datasets.ImageFolder` to load lung image data (lung_aca, lung_n, lung_scc). \n",
    "We also apply necessary transformations (resizing, normalization), split the dataset into training and validation sets, \n",
    "and prepare DataLoaders with GPU support.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35c614a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T08:03:15.171724Z",
     "iopub.status.busy": "2024-03-16T08:03:15.170129Z",
     "iopub.status.idle": "2024-03-16T08:03:15.181576Z",
     "shell.execute_reply": "2024-03-16T08:03:15.180482Z"
    },
    "papermill": {
     "duration": 0.029321,
     "end_time": "2024-03-16T08:03:15.184638",
     "exception": false,
     "start_time": "2024-03-16T08:03:15.155317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to load the dataset from the specified directory\n",
    "def loading_the_data(data_dir):\n",
    "\n",
    "    # Initialize empty lists to store file paths and corresponding labels\n",
    "    filepaths = []  # List to hold paths of the images\n",
    "    labels = []     # List to hold the labels (folder names)\n",
    "\n",
    "    # Get the list of subdirectories (each represents a class label)\n",
    "    folds = os.listdir(data_dir)\n",
    "\n",
    "    # Loop through each subdirectory\n",
    "    for fold in folds:\n",
    "        foldpath = os.path.join(data_dir, fold)  # Get the path of the subdirectory\n",
    "        filelist = os.listdir(foldpath)  # Get the list of files in the subdirectory\n",
    "\n",
    "        # Loop through each file in the subdirectory\n",
    "        for file in filelist:\n",
    "            fpath = os.path.join(foldpath, file)  # Get the full file path\n",
    "            \n",
    "            filepaths.append(fpath)  # Add the file path to the list\n",
    "            labels.append(fold)      # Add the label (folder name) to the list\n",
    "\n",
    "    # Convert the lists into pandas Series\n",
    "    Fseries = pd.Series(filepaths, name='filepaths')  # Series for file paths\n",
    "    Lseries = pd.Series(labels, name='labels')        # Series for labels\n",
    "\n",
    "    # Concatenate the two Series into a single DataFrame\n",
    "    df = pd.concat([Fseries, Lseries], axis=1)\n",
    "    \n",
    "    return df  # Return the DataFrame containing the file paths and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e405a77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T08:03:15.211545Z",
     "iopub.status.busy": "2024-03-16T08:03:15.211194Z",
     "iopub.status.idle": "2024-03-16T08:03:16.835110Z",
     "shell.execute_reply": "2024-03-16T08:03:16.834138Z"
    },
    "papermill": {
     "duration": 1.639703,
     "end_time": "2024-03-16T08:03:16.837424",
     "exception": false,
     "start_time": "2024-03-16T08:03:15.197721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the path to the dataset directory\n",
    "data_dir = './lung_colon_image_set/lung_image_sets'  # Update the path based on your current directory structure\n",
    "\n",
    "# Load the data using the function\n",
    "df = loading_the_data(data_dir)\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc164de",
   "metadata": {
    "papermill": {
     "duration": 0.009689,
     "end_time": "2024-03-16T08:03:16.857498",
     "exception": false,
     "start_time": "2024-03-16T08:03:16.847809",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca58c63",
   "metadata": {},
   "source": [
    "##### Random Images from Three Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5e87cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique class names\n",
    "class_names = sorted(df['labels'].unique())\n",
    "num_classes = len(class_names)\n",
    "\n",
    "selected_classes = class_names[:3] \n",
    "num_images_per_class = 3  \n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for idx, class_name in enumerate(selected_classes):\n",
    "    class_df = df[df['labels'] == class_name]\n",
    "    \n",
    "    random_samples = class_df.sample(num_images_per_class)\n",
    "    \n",
    "    for i, (_, row) in enumerate(random_samples.iterrows()):\n",
    "        image_path = row['filepaths']\n",
    "        \n",
    "        image = plt.imread(image_path)\n",
    "        \n",
    "        plt.subplot(3, len(selected_classes), idx * num_images_per_class + i + 1)\n",
    "        plt.imshow(image)\n",
    "        plt.title(f\"Class: {class_name}\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f896e67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T08:03:16.879414Z",
     "iopub.status.busy": "2024-03-16T08:03:16.879033Z",
     "iopub.status.idle": "2024-03-16T08:03:17.057121Z",
     "shell.execute_reply": "2024-03-16T08:03:17.056059Z"
    },
    "papermill": {
     "duration": 0.194225,
     "end_time": "2024-03-16T08:03:17.062257",
     "exception": false,
     "start_time": "2024-03-16T08:03:16.868032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_balance = df.labels.value_counts()\n",
    "\n",
    "# Data Balance Pie Chart with enhanced details\n",
    "def custom_autopct(pct):\n",
    "    total = sum(data_balance)\n",
    "    val = int(round(pct*total/100.0))\n",
    "    return \"{:.1f}%\\n({:d})\".format(pct, val)\n",
    "\n",
    "# Pie Chart\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.pie(data_balance, labels=data_balance.index, autopct=custom_autopct, colors=[\"#2092E6\", \"#6D8CE6\", \"#20D0E6\"])\n",
    "plt.title(\"Training Data Balance\")\n",
    "plt.axis(\"equal\")\n",
    "plt.show()\n",
    "\n",
    "# Bar Chart for Category Distribution\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.barplot(x=data_balance.index, y=data_balance.values, palette=\"Blues_d\")\n",
    "plt.title(\"Training Data Distribution (Bar Chart)\")\n",
    "plt.xlabel(\"Category\")\n",
    "plt.ylabel(\"Number of Samples\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Additional Statistical Info (Number of categories, mean, median, etc.)\n",
    "print(\"Statistical Summary of the Data Balance:\")\n",
    "print(data_balance.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825357a2",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing and Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c07c6cf",
   "metadata": {},
   "source": [
    "##### Dataset Preparation\n",
    "We will use the custom LungDataset class to wrap our DataFrame objects and prepare them for PyTorch models using DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806439f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom PyTorch Dataset class\n",
    "class LungDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.df = dataframe.reset_index(drop=True)  # reset index to ensure continuous indices\n",
    "        self.transform = transform  # image transformations (e.g. resizing, normalization)\n",
    "        self.label2idx = {label: idx for idx, label in enumerate(sorted(self.df['labels'].unique()))}\n",
    "        \n",
    "        print(f\"Dataset loaded with {len(self.df)} samples.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)  # total number of samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.df.loc[idx, 'filepaths']  # get image file path\n",
    "        label = self.label2idx[self.df.loc[idx, 'labels']]  # convert label to index\n",
    "        \n",
    "        image = Image.open(image_path)  # open image\n",
    "        if self.transform:\n",
    "            image = self.transform(image)  # apply transformations (e.g. ToTensor)\n",
    "\n",
    "        return image, label  # return transformed image and numeric label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fddeae4",
   "metadata": {},
   "source": [
    "##### Image Transforms\n",
    "We use torchvision.transforms to resize, normalize, and convert images into PyTorch tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc9da46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define standard transforms (Resizing, Tensor conversion, Normalization)\n",
    "img_size = 224\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f544fe",
   "metadata": {},
   "source": [
    "##### Splitting the Dataset\n",
    "We split the original DataFrame into train, validation, and test sets (80/10/10 split)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f55b694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80% train, 20% temp (validation + test)\n",
    "train_df, temp_df = train_test_split(df, train_size=0.8, shuffle=True, random_state=42)\n",
    "\n",
    "# 10% validation, 10% test\n",
    "valid_df, test_df = train_test_split(temp_df, train_size=0.5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8688a9b9",
   "metadata": {},
   "source": [
    "##### Data Split Visualization\n",
    "This pie chart shows the proportion of the dataset split into training, validation, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa54e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the sizes of each split\n",
    "sizes = [len(train_df), len(valid_df), len(test_df)]\n",
    "labels = ['Train', 'Validation', 'Test']\n",
    "\n",
    "# Plotting the split as a pie chart\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90, colors=['#66b3ff','#99ff99','#ffcc99'])\n",
    "plt.title('Data Split Visualization')\n",
    "plt.axis('equal')  # Equal aspect ratio for a perfect circle\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd03235",
   "metadata": {},
   "source": [
    "##### Creating Dataset and DataLoaders\n",
    "Now we wrap each split in the custom dataset and use DataLoader for batch processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640b0cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create dataset objects\n",
    "train_dataset = LungDataset(train_df, transform=transform)\n",
    "valid_dataset = LungDataset(valid_df, transform=transform)\n",
    "test_dataset  = LungDataset(test_df, transform=transform)\n",
    "\n",
    "# Create DataLoader objects for batching\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=0, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, num_workers=0, shuffle=False)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, num_workers=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ff83c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv_stack = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(128 * (img_size // 8) * (img_size // 8), 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_stack(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22700028",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNModel(num_classes=len(class_names)).to(device) \n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00ea875",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adb1ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    print(\"Starting training loop...\")\n",
    "    \n",
    "    epoch_start_time = time.time()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss_val = loss.item()\n",
    "            current = (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss_val:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    \n",
    "    epoch_end_time = time.time()\n",
    "    epoch_duration = epoch_end_time - epoch_start_time\n",
    "    print(f\"Epoch completed in {epoch_duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc7dcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader, model, loss_fn, name=\"Test\"):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    \n",
    "    epoch_start_time = time.time()  # Değerlendirme başı zamanı kaydet\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    \n",
    "    epoch_end_time = time.time()  # Değerlendirme bitiş zamanı\n",
    "    epoch_duration = epoch_end_time - epoch_start_time  # Epoch süresi\n",
    "    \n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"{name} Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:.4f}\")\n",
    "    print(f\"{name} evaluation completed in {epoch_duration:.2f} seconds\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6029d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop with validation\n",
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_loader, model, loss_fn, optimizer)\n",
    "    evaluate(valid_loader, model, loss_fn, name=\"Validation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6242d5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final test evaluation\n",
    "evaluate(test_loader, model, loss_fn, name=\"Test\")\n",
    "print(\"Testing complete!\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 601280,
     "sourceId": 1079953,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30665,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3919.544519,
   "end_time": "2024-03-16T09:08:17.109414",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-16T08:02:57.564895",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
