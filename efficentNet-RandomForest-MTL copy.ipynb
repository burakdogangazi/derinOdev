{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4777bdf8",
   "metadata": {
    "papermill": {
     "duration": 0.009896,
     "end_time": "2024-03-16T08:03:00.449654",
     "exception": false,
     "start_time": "2024-03-16T08:03:00.439758",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Import Needed Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c1c6a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T08:03:00.469203Z",
     "iopub.status.busy": "2024-03-16T08:03:00.468874Z",
     "iopub.status.idle": "2024-03-16T08:03:15.111058Z",
     "shell.execute_reply": "2024-03-16T08:03:15.110163Z"
    },
    "papermill": {
     "duration": 14.654558,
     "end_time": "2024-03-16T08:03:15.113502",
     "exception": false,
     "start_time": "2024-03-16T08:03:00.458944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- General Libraries ---\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# --- Data Handling ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# --- Image Handling and Visualization ---\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "\n",
    "# --- PyTorch and Deep Learning ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "\n",
    "# --- Warning Suppression ---\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bbb7c8",
   "metadata": {},
   "source": [
    "## 2. Device Configuration\n",
    "\n",
    "In this section, we configure the device for PyTorch computations. If a CUDA-enabled GPU is available, it will be used for faster processing. Otherwise, the computations will fall back to the CPU. Additional details about the CUDA device are also printed if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33cc41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device for PyTorch computations\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Print device information\n",
    "print(f\"Using {device} device\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# If CUDA is available, print additional details\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Number of CUDA Devices: {torch.cuda.device_count()}\")\n",
    "    print(f\"Current CUDA Device: {torch.cuda.current_device()}\")\n",
    "    print(f\"CUDA Device Name: {torch.cuda.get_device_name(torch.cuda.current_device())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ded9ef8",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35c614a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T08:03:15.171724Z",
     "iopub.status.busy": "2024-03-16T08:03:15.170129Z",
     "iopub.status.idle": "2024-03-16T08:03:15.181576Z",
     "shell.execute_reply": "2024-03-16T08:03:15.180482Z"
    },
    "papermill": {
     "duration": 0.029321,
     "end_time": "2024-03-16T08:03:15.184638",
     "exception": false,
     "start_time": "2024-03-16T08:03:15.155317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "root_dir = \"lung_colon_image_set\"\n",
    "image_paths = []\n",
    "binary_labels = []\n",
    "multi_labels = []\n",
    "\n",
    "label_mapping = {\n",
    "    'lung_n': 0, 'lung_aca': 1, 'lung_scc': 2,\n",
    "    'colon_n': 3, 'colon_aca': 4\n",
    "}\n",
    "\n",
    "binary_mapping = {\n",
    "    'lung_n': 0, 'colon_n': 0,\n",
    "    'lung_aca': 1, 'lung_scc': 1, 'colon_aca': 1\n",
    "}\n",
    "\n",
    "for subfolder in ['lung_image_sets/lung_n', 'lung_image_sets/lung_aca', 'lung_image_sets/lung_scc',\n",
    "                  'colon_image_sets/colon_n', 'colon_image_sets/colon_aca']:\n",
    "    class_dir = os.path.join(root_dir, subfolder)\n",
    "    class_name = subfolder.split('/')[-1]\n",
    "\n",
    "    for img_file in os.listdir(class_dir):\n",
    "        img_path = os.path.join(class_dir, img_file)\n",
    "        image_paths.append(img_path)\n",
    "        multi_labels.append(label_mapping[class_name])\n",
    "        binary_labels.append(binary_mapping[class_name])\n",
    "\n",
    "print(f\"Total Image: {len(image_paths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f6bbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(), \n",
    "    transforms.RandomRotation(15),  \n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),  # Random color jitter\n",
    "    transforms.RandomZoom(0.1), \n",
    "    transforms.RandomVerticalFlip(), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalization\n",
    "])\n",
    "\n",
    "# Regular transform for test/validation data (no augmentation)\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c39bd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureDataset(Dataset):\n",
    "    def __init__(self, image_paths, binary_labels, multi_labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.binary_labels = binary_labels\n",
    "        self.multi_labels = multi_labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, self.binary_labels[idx], self.multi_labels[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476933b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_bin_train, y_bin_test, y_multi_train, y_multi_test = train_test_split(\n",
    "    image_paths, binary_labels, multi_labels,\n",
    "    test_size=0.3, random_state=42, stratify=multi_labels\n",
    ")\n",
    "\n",
    "# Create datasets with respective transformations\n",
    "train_dataset = FeatureDataset(X_train, y_bin_train, y_multi_train, transform=train_transform)\n",
    "test_dataset = FeatureDataset(X_test, y_bin_test, y_multi_test, transform=test_transform)\n",
    "\n",
    "# Create data loaders for train and test datasets\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba42f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.efficientnet_b3(weights=models.EfficientNet_B3_Weights.DEFAULT)\n",
    "model.classifier = torch.nn.Identity() \n",
    "model = model.to(device)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac405895",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(dataloader):\n",
    "    all_features = []\n",
    "    all_bin_labels = []\n",
    "    all_multi_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, bin_labels, multi_labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            features = model(inputs)\n",
    "            all_features.append(features.cpu().numpy())\n",
    "            all_bin_labels.extend(bin_labels)\n",
    "            all_multi_labels.extend(multi_labels)\n",
    "\n",
    "    return np.concatenate(all_features), np.array(all_bin_labels), np.array(all_multi_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc422515",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_feat, y_bin_train, y_multi_train = extract_features(train_loader)\n",
    "X_test_feat, y_bin_test, y_multi_test = extract_features(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6998a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_binary = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_binary.fit(X_train_feat, y_bin_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7999a1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_bin_pred = rf_binary.predict(X_test_feat)\n",
    "\n",
    "print(\"ðŸ”Ž Binary Classification Report:\")\n",
    "print(classification_report(y_bin_test, y_bin_pred, target_names=[\"Benign\", \"Malignant\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189da997",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_multi = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_multi.fit(X_train_feat, y_multi_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56e9db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_multi_pred = rf_multi.predict(X_test_feat)\n",
    "\n",
    "print(\"ðŸ”Ž Multiclass Classification Report:\")\n",
    "print(classification_report(y_multi_test, y_multi_pred, target_names=[\n",
    "    \"Lung Benign\", \"Lung ACA\", \"Lung SCC\", \"Colon Benign\", \"Colon ACA\"\n",
    "]))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 601280,
     "sourceId": 1079953,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30665,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3919.544519,
   "end_time": "2024-03-16T09:08:17.109414",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-16T08:02:57.564895",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
