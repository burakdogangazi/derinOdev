{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4777bdf8",
   "metadata": {
    "papermill": {
     "duration": 0.009896,
     "end_time": "2024-03-16T08:03:00.449654",
     "exception": false,
     "start_time": "2024-03-16T08:03:00.439758",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Import needed libraries and Set Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c1c6a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T08:03:00.469203Z",
     "iopub.status.busy": "2024-03-16T08:03:00.468874Z",
     "iopub.status.idle": "2024-03-16T08:03:15.111058Z",
     "shell.execute_reply": "2024-03-16T08:03:15.110163Z"
    },
    "papermill": {
     "duration": 14.654558,
     "end_time": "2024-03-16T08:03:15.113502",
     "exception": false,
     "start_time": "2024-03-16T08:03:00.458944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\burakdogan\\Desktop\\lc2500-Not_Working\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# --- General Libraries ---\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "# --- Data Handling ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# --- Image Handling and Visualization ---\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# --- PyTorch and Deep Learning ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import timm  # For EfficientNet and other pretrained models\n",
    "\n",
    "# --- Utilities ---\n",
    "from tqdm import tqdm  # For training progress visualization\n",
    "import torch.profiler  # Optional: For GPU usage profiling\n",
    "\n",
    "# --- Warning Suppression ---\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b33cc41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "True\n",
      "1\n",
      "0\n",
      "NVIDIA GeForce RTX 4060 Ti\n"
     ]
    }
   ],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13260370",
   "metadata": {
    "papermill": {
     "duration": 0.013127,
     "end_time": "2024-03-16T08:03:15.143475",
     "exception": false,
     "start_time": "2024-03-16T08:03:15.130348",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 2. Data Loading and Preprocessing\n",
    "\n",
    "In this section, we use `torchvision.datasets.ImageFolder` to load lung image data (lung_aca, lung_n, lung_scc). \n",
    "We also apply necessary transformations (resizing, normalization), split the dataset into training and validation sets, \n",
    "and prepare DataLoaders with GPU support.\n",
    "\n",
    "```bash\n",
    "lung_colon_image_set/\n",
    "├── colon_image_sets/\n",
    "│   ├── colon_aca/\n",
    "│   └── colon_n/\n",
    "└── lung_image_sets/\n",
    "    ├── lung_aca/\n",
    "    ├── lung_n/\n",
    "    └── lung_scc/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfb56fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary classification: 0 = benign, 1 = malignant\n",
    "binary_labels_map = {\n",
    "    \"lung_n\": 0,\n",
    "    \"colon_n\": 0,\n",
    "    \"lung_aca\": 1,\n",
    "    \"lung_scc\": 1,\n",
    "    \"colon_aca\": 1\n",
    "}\n",
    "\n",
    "# Multiclass classification: 5 class (0–4)\n",
    "multiclass_labels_map = {\n",
    "    \"colon_aca\": 0,\n",
    "    \"lung_aca\": 1,\n",
    "    \"lung_scc\": 2,\n",
    "    \"colon_n\": 3,\n",
    "    \"lung_n\": 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e0b8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = []\n",
    "binary_labels = []\n",
    "multi_labels = []\n",
    "\n",
    "root_dir = \"lung_colon_image_set\"\n",
    "\n",
    "for class_name in multiclass_labels_map:\n",
    "    label_bin = binary_labels_map[class_name]\n",
    "    label_multi = multiclass_labels_map[class_name]\n",
    "\n",
    "    if \"lung\" in class_name:\n",
    "        class_path = os.path.join(root_dir, \"lung_image_sets\", class_name)\n",
    "    else:\n",
    "        class_path = os.path.join(root_dir, \"colon_image_sets\", class_name)\n",
    "\n",
    "    for img_file in glob.glob(os.path.join(class_path, \"*.jpeg\")):\n",
    "        image_paths.append(img_file)\n",
    "        binary_labels.append(label_bin)\n",
    "        multi_labels.append(label_multi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c1beea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# İlk olarak train + temp (val+test) olarak bölüyoruz\n",
    "X_train, X_temp, y_bin_train, y_bin_temp, y_multi_train, y_multi_temp = train_test_split(\n",
    "    image_paths, binary_labels, multi_labels,\n",
    "    test_size=0.3, random_state=42, stratify=multi_labels\n",
    ")\n",
    "\n",
    "# Temp'i val ve test olarak ayırıyoruz\n",
    "X_val, X_test, y_bin_val, y_bin_test, y_multi_val, y_multi_test = train_test_split(\n",
    "    X_temp, y_bin_temp, y_multi_temp,\n",
    "    test_size=0.5, random_state=42, stratify=y_multi_temp\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ef2eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MTLImageDataset(Dataset):\n",
    "    def __init__(self, image_paths, binary_labels, multi_labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.binary_labels = binary_labels\n",
    "        self.multi_labels = multi_labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, {\n",
    "            \"binary_output\": self.binary_labels[idx],\n",
    "            \"multi_output\": self.multi_labels[idx]\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdb04dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transforms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m transform \u001b[38;5;241m=\u001b[39m \u001b[43mtransforms\u001b[49m\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[0;32m      2\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mResize((\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m)),\n\u001b[0;32m      3\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mToTensor()\n\u001b[0;32m      4\u001b[0m ])\n\u001b[0;32m      6\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m MTLImageDataset(X_train, y_bin_train, y_multi_train, transform\u001b[38;5;241m=\u001b[39mtransform)\n\u001b[0;32m      7\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m MTLImageDataset(X_val, y_bin_val, y_multi_val, transform\u001b[38;5;241m=\u001b[39mtransform)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'transforms' is not defined"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = MTLImageDataset(X_train, y_bin_train, y_multi_train, transform=transform)\n",
    "val_dataset = MTLImageDataset(X_val, y_bin_val, y_multi_val, transform=transform)\n",
    "test_dataset = MTLImageDataset(X_test, y_bin_test, y_multi_test, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a0ea86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MTLModel(nn.Module):\n",
    "    def __init__(self, num_classes_multiclass=5):\n",
    "        super(MTLModel, self).__init__()\n",
    "\n",
    "        # Load EfficientNetB3 backbone\n",
    "        self.backbone = models.efficientnet_b3(weights=models.EfficientNet_B3_Weights.DEFAULT)\n",
    "\n",
    "        # Freeze early layers if needed\n",
    "        for param in self.backbone.features.parameters():\n",
    "            param.requires_grad = True  # or False to freeze\n",
    "\n",
    "        # Shared feature extractor\n",
    "        self.shared_features = self.backbone.features\n",
    "        self.pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # Binary classification head (cancer present or not)\n",
    "        self.binary_classifier = nn.Sequential(\n",
    "            nn.Linear(1536, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        # Multiclass classification head (cancer type)\n",
    "        self.multiclass_classifier = nn.Sequential(\n",
    "            nn.Linear(1536, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes_multiclass)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.shared_features(x)\n",
    "        x = self.pooling(x)\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        binary_output = self.binary_classifier(x).squeeze(1)  # shape: (batch_size,)\n",
    "        multiclass_output = self.multiclass_classifier(x)     # shape: (batch_size, num_classes)\n",
    "\n",
    "        return {\n",
    "            \"binary_output\": binary_output,\n",
    "            \"multi_output\": multiclass_output\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4447e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, optimizer, num_epochs=10):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    criterion_binary = nn.BCELoss()\n",
    "    criterion_multiclass = nn.CrossEntropyLoss()\n",
    "\n",
    "    history = {\"train_loss\": [], \"val_loss\": []}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            for inputs, binary_labels, multi_labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                binary_labels = binary_labels.float().to(device)\n",
    "                multi_labels = multi_labels.long().to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss_binary = criterion_binary(outputs['binary_output'], binary_labels)\n",
    "                    loss_multiclass = criterion_multiclass(outputs['multi_output'], multi_labels)\n",
    "\n",
    "                    loss = loss_binary + loss_multiclass\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            history[f\"{phase}_loss\"].append(epoch_loss)\n",
    "\n",
    "            print(f\"{phase} Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89edcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(history):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(history['train_loss'], label='Train Loss')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training & Validation Loss Over Epochs')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a456072",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    all_binary_preds = []\n",
    "    all_binary_labels = []\n",
    "\n",
    "    all_multi_preds = []\n",
    "    all_multi_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, binary_labels, multi_labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            binary_labels = binary_labels.to(device)\n",
    "            multi_labels = multi_labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Binary predictions\n",
    "            binary_probs = outputs['binary_output']\n",
    "            binary_preds = (binary_probs > 0.5).int()\n",
    "\n",
    "            # Multiclass predictions\n",
    "            multi_logits = outputs['multi_output']\n",
    "            multi_preds = torch.argmax(multi_logits, dim=1)\n",
    "\n",
    "            all_binary_preds.extend(binary_preds.cpu().numpy())\n",
    "            all_binary_labels.extend(binary_labels.cpu().numpy())\n",
    "\n",
    "            all_multi_preds.extend(multi_preds.cpu().numpy())\n",
    "            all_multi_labels.extend(multi_labels.cpu().numpy())\n",
    "\n",
    "    # Metrics for Binary Classification\n",
    "    print(\"🔍 Binary Classification Results:\")\n",
    "    print(\"Accuracy:\", accuracy_score(all_binary_labels, all_binary_preds))\n",
    "    print(\"Precision:\", precision_score(all_binary_labels, all_binary_preds))\n",
    "    print(\"Recall:\", recall_score(all_binary_labels, all_binary_preds))\n",
    "    print(\"F1 Score:\", f1_score(all_binary_labels, all_binary_preds))\n",
    "\n",
    "    # Confusion Matrix - Binary\n",
    "    cm_bin = confusion_matrix(all_binary_labels, all_binary_preds)\n",
    "    plt.figure(figsize=(5,4))\n",
    "    sns.heatmap(cm_bin, annot=True, fmt='d', cmap='Blues', xticklabels=['Benign', 'Malignant'], yticklabels=['Benign', 'Malignant'])\n",
    "    plt.title('Confusion Matrix - Binary Classification')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "\n",
    "    # Metrics for Multiclass Classification\n",
    "    print(\"\\n🎯 Multiclass Classification Results:\")\n",
    "    print(classification_report(all_multi_labels, all_multi_preds, target_names=[\n",
    "        'Colon ACA', 'Lung ACA', 'Lung SCC', 'Colon N', 'Lung N'\n",
    "    ]))\n",
    "\n",
    "    # Confusion Matrix - Multiclass\n",
    "    cm_multi = confusion_matrix(all_multi_labels, all_multi_preds)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.heatmap(cm_multi, annot=True, fmt='d', cmap='YlGnBu', xticklabels=[\n",
    "        'Colon ACA', 'Lung ACA', 'Lung SCC', 'Colon N', 'Lung N'\n",
    "    ], yticklabels=[\n",
    "        'Colon ACA', 'Lung ACA', 'Lung SCC', 'Colon N', 'Lung N'\n",
    "    ])\n",
    "    plt.title('Confusion Matrix - Multiclass Classification')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485a5a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = MTLModel(num_classes_multiclass=5).to(device)\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd73a0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "evaluate_model(model, test_loader)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 601280,
     "sourceId": 1079953,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30665,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3919.544519,
   "end_time": "2024-03-16T09:08:17.109414",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-16T08:02:57.564895",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
